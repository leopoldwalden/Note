NLP算法研发：
文本分类：SVM；FastText；Text-CNN
		SVM：Hinge Loss
			核函数：

命名实体识别：1.bert, crf, bi-lstm
			1)bert: embedding + finetune 两种任务共享权重训练得到(传统模型，从左至右训练)；
				Bi-direction transformer -> Mask 形状
				XLnet: factorizing 用乱序输入代替随机mask，增加计算量
				finetune: isNext -> cls classifier
						  NER -> Token Classification
						  (finetune的问题：参数量大，能否固定模型，只调整后面两层)
				分词的问题：one-hot：维度爆炸/embedding->样本稀疏
		    2.transformer：q、k、v self-attention
		   			   (query来自于之前一级的decoder层的输出，但其key和value来自于encoder的输出)
		   		*[trick] pytorch transformer: mask 采用(0,inf); 其他transformer: mask 采用(0,1);
		   				存在的问题：inf有一些不确定的行为：0×inf、inf-inf
		      norm层 layer-norm
		    3. crf: 用马尔科夫模型描述一个序列的转移概率，将隐状态节点在时间轴上展开，问题转化为路径搜索问题。
		    逐帧输出没有考虑到上下文的关联，找出最大可能的路径（每次损失函数的构成都因为crf有所变化）
				 viterbi /beam search
			
小数据量学习：对于深度学习任何情况下都困难，1.transfer learning 
						  2.LSTM

数据不平衡：1.欠采样：数据变少；
		  2.过采样：效果一般；
		  3.调阈值：work，可引入先验

Hierarchical Classification：1.场景-数据量少/类别多：树状结构标签，一般都是类别太多，数据分布较为稀疏的情况，
							 2.分层分类；
							 3.对标签进行路径搜索；
							 # 4.对标签进行encoding，取
Flask部署模型供下游使用

中文多轮对话系统研发
流程： 1.对话内容解析: 情感分析(正面-负面)/意图识别/问句匹配/事务推理
		1）情感分析：词典；深度学习
		2）意图识别：分类方法：买XX机票->买机票/买XX火车票->买火车票；存在的问题：无意图对象很难区分
					PCA:n维降到K维：求协方差阵->SVD->取K个特征最大的维度作为新维度
				   句法分析：买XXX机票 -> 动宾结构（买机票）	
		3）问句匹配：elasticsearch
				   相似度计算: 语义相关: 余弦相似度(BERT)(上下文相关，双向transformer) / 欧氏距离(word2vec): 
				   			 非语义相关: 编辑距离
				   		[Trick]将问题和答案作为整体进行匹配
		*4）事务推理：
	  2. 知识索引： 根据槽位填充预先设计sql；难点：根据文本解析得到的逻辑生成SQL
DST对话状态追踪问题：效果都不好；解决方法：1.memory机制->前文状态；事务栈
主要负责，提高对话意图识别准确率：1.分类问题，e.g. 问句和非问句；
				    		2.实体识别问题 -> 事务栈；
				    		3.指代消歧、状态追踪
				    			1) 指代消歧：句法分析，一阶逻辑
				    			2）状态追踪：Frame-based DM/事务栈、修复请求/轮询
设计对话Story：1.专家系统，对话模板。
			 2.open domain chatbot，生成式模型

对话数据主题提取：
	关键词提取：TF-IDF；LDA；倒排索引；TextRank
			LDA: 使类间距尽可能大，使类内距离尽可能小
	事务推理：


ASR语音识别模型实现：
研究基于中文语料的端到端ASR模型：1.listner、encoder、speller
						   2.Jasper/VGG net+Transformer
使用ctc处理连续时序列样本的对齐问题：
					CTC Loss: 对齐问题需要与标签做减法，求最小；CTC计算序列的概率，求最大，不需要标签相减，也就不需要对齐
						#每种输入序列有多种可能的输出序列，计算所有可能的序列，再在上面计算loss predict时用不到CTC

模型调优：
监控模型训练过程：1.loss 大幅度变化/下降开始下降太快然后又不动，
							e.g. 1）模型写错 batch norm 在全连接后，在激活函数前（激活函数会改变分布）
								 2）dropout 
								 3）Relu: 解决梯度消失问题；PRelu：解决Relu的网络坏死问题
			   2. early stop
对模型学习过程进行分析
调整模型结构和参数、选择合适的优化策略，最终实现合理的收敛过程和理想的收敛结果；
overfitting: 正则化->引入稀疏解（稀疏解可以降低内存和运算）;过拟合体现出来的现象就是特征权重𝑊的各个维度的绝对值非常大:一些大正数，一些大负数


后台算法实现：
面向业务场景设计后台算法，设计数据库作业脚本：1.客服对话event搜索，成单率计算
									 2.数据脱敏 


设计业务场景：
针对门诊场景构建AI处方审核系统。利用知识图谱解决医疗诊断场景中的不合理用药问题：难点 -> 构建知识图谱
架构设计和工程实现：
项目技术架构选型，
拟定技术方案；
工作量把控，在产品实现过程中的技术先进性需求和工程实现能力之间进行平衡，控制项目进度。
关系抽取：1.实体识别
		2.指代消歧：没做
		3.远监督：用已有KG判断句子中的三元组是否可信
文本分类，生产构建图谱所需三元组，基于知识图谱进行项目功能实现。
利用bootstrap思想对NER过程进行迭代，以解决数据不足的问题：
		冷启动问题，在样本中混入可信的预测结果，模拟又放回的抽样（原本为重采样，用采样的结果估计真实样本的分布）
模型研究：
尝试Trans系列和Node2vec系列方法对构建好的图谱进行图嵌入：
		1.TransE encode 关系和实体，反复替换head/tail，以正确三元组为标签，保证head-tail~=relatio
		2.Node2Vec 采用deepwalk遍历图结构，构造序列（类似word2vec）
利用embedding模型实现图谱的半自动化构建和对三元组的置信度分析：
		1. 判断new_ent的置信度： 没做
		2. 判断new_relation的置信度：拿到两个已经存在的ent，可达路径越多(路由算法)，relation越可靠
从而实现图谱从拓展到评估再到拓展的迭代循环。

DBSCAN：以领域和密度为核心的聚类算法->解决聚类形状问题（Kmeans只能处理球形的聚类结果）
		聚类结果评价指标：1）内部指标：
					   2）外部指标：需要真实数据作为依据

============================================================================
朴素贝叶斯：

线性回归：拟合，最小二乘估计

GBDT:基于回归树，回归树->弱分类器->在残差上构建弱分类器->集成

决策树：ID3信息熵增益/C4.5信息熵增益率

Random Forest：分组抽样 -> 组合多个分类器（bagging）

L1/L2 形状

-----------------------
最拿手项目

非递归遍历

最近公共祖先

how to train word2vec? groud-truth

最短路径

优化算法

self-attention q k v

----------------

树方法（回归/决策）= 对数据集的一种划分 + 在每个划分上的取值
			决策树 = 划分 + 取值 （取值={0,1}）
			回归树 = 划分 + 取值 （取值 = average(data) data为叶子节点上所有的训练数据）



============================================================

basic CS

TCP:
	不同协议本质上都是为了防止无限等待和死锁设计的
	三次握手：
		1) 为什么是三次不是更多次：当然可以更多次，可以无限次，三次是最小次数
		2) 为什么不能是两次：三次握手中，服务端收到两次信号，一次SYN，一次ACK，本质上只有这两个信号成对出现，才能确保一个有效的连接请求，
		   而不是之前失效的连接请求又被误收
	四次挥手：

